{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cross-Encoder\n\n<br>\n\n![ce](https://weaviate.io/assets/images/cross-encoder-61b340b8d1f6359bb7650da2c59be11c.png)\n\n<br>\n\n## Cos'è un cross-encoder?\n\nUn [Cross-Encoder](https://arxiv.org/abs/1908.10084) è un classificatore di coppie di frasi. Richiede in input una coppia di testi e ne classifica la similarità mediante un indice tra 0 e 1. A differenza dei [Bi-Encoder](https://arxiv.org/abs/1908.10084) non calcola gli embeddings della frase.\n\n## Differenza tra bi-encoder e cross-encoder\n\nUn **Bi-Encoder** prende in input una frase alla volta e ne calcola l'embedding. Per capire la similarità tra frasi su questi embeddings va calcolata una misura di similarità come la [similarità del coseno](https://it.wikipedia.org/wiki/Coseno_di_similitudine) o il [prodotto scalare](https://it.wikipedia.org/wiki/Prodotto_scalare).\n\nUn **Cross-Encoder** prende in input una coppia di frasi simultaneamente, non ne calcola gli embeddings, ma le classifica secondo un indice di similarità compreso tra 0 e 1.\n\n<br>\n\n![bicross](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/Bi_vs_Cross-Encoder.png)\n\n<br>\n\n> N.B. se si vuole applicare il prodotto scalare assicurarsi che gli embeddings siano normalizzati","metadata":{}},{"cell_type":"markdown","source":"## Training di un Cross-Encoder usando [SBERT](https://www.sbert.net/)\n\nDi seguito un esempio della creazione di un Cross-Encoder per l'italiano con la libreria sentence-transformers. Come per i Bi-Encoder ci sono diversi metodi per farlo a seconda del dataset scelto, qui verrà usato sempre un dataset formato Semantic Textual Similarity (STS) benchmark.","metadata":{}},{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-10T10:21:26.725462Z","iopub.execute_input":"2023-05-10T10:21:26.725894Z","iopub.status.idle":"2023-05-10T10:21:41.637446Z","shell.execute_reply.started":"2023-05-10T10:21:26.725854Z","shell.execute_reply":"2023-05-10T10:21:41.636184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:21:41.641527Z","iopub.execute_input":"2023-05-10T10:21:41.641875Z","iopub.status.idle":"2023-05-10T10:21:53.929727Z","shell.execute_reply.started":"2023-05-10T10:21:41.641838Z","shell.execute_reply":"2023-05-10T10:21:53.928466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset\n\nA seguito dello scaricamento del [dataset da Huggingface Hub](https://huggingface.co/datasets/stsb_multi_mt/viewer/it/train) bisogna preparare le coppie di frasi per il modello.\n\nIl processo è molto simile a quello del Bi-Encoder ma qui, nel dataset di train le coppie vanno inserite in entrambe le combinazione quindi:\n* ([frase1, frase2], sim)\n* ([frase2, frase1], sim)\n\nperchè lo score deve essere simmetrico.\nPer il dataset di valutazione e/o test non c'è bisogno.\n\n> Per maggiori info sulle altre tecniche consultare gli [esempi](https://www.sbert.net/examples/training/cross-encoder/README.html#examples).","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom sentence_transformers import InputExample\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:21:53.932724Z","iopub.execute_input":"2023-05-10T10:21:53.933147Z","iopub.status.idle":"2023-05-10T10:22:00.155335Z","shell.execute_reply.started":"2023-05-10T10:21:53.933099Z","shell.execute_reply":"2023-05-10T10:22:00.154230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"train\")\ndataset_test = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"test\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:00.157183Z","iopub.execute_input":"2023-05-10T10:22:00.158340Z","iopub.status.idle":"2023-05-10T10:22:03.148455Z","shell.execute_reply.started":"2023-05-10T10:22:00.158291Z","shell.execute_reply":"2023-05-10T10:22:03.147425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gold_samples = []\nbatch_size = 16\nfor df in dataset_train:\n    score = float(df['similarity_score'])/5.0 \n    gold_samples.append(InputExample(texts=[df['sentence1'], df['sentence2']], label=score))\n    gold_samples.append(InputExample(texts=[df['sentence2'], df['sentence1']], label=score))\n\ntrain_dataloader = DataLoader(gold_samples, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:03.152657Z","iopub.execute_input":"2023-05-10T10:22:03.153629Z","iopub.status.idle":"2023-05-10T10:22:03.601419Z","shell.execute_reply.started":"2023-05-10T10:22:03.153585Z","shell.execute_reply":"2023-05-10T10:22:03.600235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\nimport math\n# We add an evaluator, which evaluates the performance during training\nevaluator = CECorrelationEvaluator([ [x['sentence1'], x['sentence2']] for x in dataset_test], [x/5.0 for x in dataset_test['similarity_score']])","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:18.131821Z","iopub.execute_input":"2023-05-10T10:22:18.134303Z","iopub.status.idle":"2023-05-10T10:22:18.254087Z","shell.execute_reply.started":"2023-05-10T10:22:18.134259Z","shell.execute_reply":"2023-05-10T10:22:18.253006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train del modello\n\nPartendo sempre da un [BERT per l'italiano](https://huggingface.co/dbmdz/bert-base-italian-uncased) creiamo il nostro cross-encoder inizializzando l'head mediante il numero di etichette da predire.\n\n> Nel nostro caso, modello STS abbiamo una solo etichetta, ovvero lo score. Se avessimo avuto un dataset formato *NLI (\"contradiction\", \"entailment\", \"neutral\")* avremmo inserito il numero delle etichette presenti.\n\nScelte il numero di epoche di addestramento e i warmup steps possiamo iniziare l'addestramento.","metadata":{}},{"cell_type":"code","source":"from sentence_transformers.cross_encoder import CrossEncoder\n\nmodel_checkpoint = \"dbmdz/bert-base-italian-uncased\"\ncross_encoder = CrossEncoder(model_checkpoint, num_labels=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:03.602848Z","iopub.execute_input":"2023-05-10T10:22:03.603530Z","iopub.status.idle":"2023-05-10T10:22:18.126422Z","shell.execute_reply.started":"2023-05-10T10:22:03.603480Z","shell.execute_reply":"2023-05-10T10:22:18.125298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 4\nevaluation_steps = 500\n\nwarmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:18.255597Z","iopub.execute_input":"2023-05-10T10:22:18.255986Z","iopub.status.idle":"2023-05-10T10:22:18.261965Z","shell.execute_reply.started":"2023-05-10T10:22:18.255945Z","shell.execute_reply":"2023-05-10T10:22:18.260756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_encoder.fit(train_dataloader=train_dataloader,\n          evaluator=evaluator,\n          epochs=num_epochs,\n          evaluation_steps=evaluation_steps,\n          warmup_steps=warmup_steps,\n          save_best_model=True,\n        output_path = \"cross-encoder-italian-bert-stsb/\")","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:22:18.263726Z","iopub.execute_input":"2023-05-10T10:22:18.264572Z","iopub.status.idle":"2023-05-10T10:47:39.224816Z","shell.execute_reply.started":"2023-05-10T10:22:18.264532Z","shell.execute_reply":"2023-05-10T10:47:39.223600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\n\nSolitamente i Cross-Encoder hanno prestazioni migliori sull'inferenza rispetto ai Bi-Encoder, in questo caso non ci siamo focalizzati sulla metrica infatti il circa 81% di accuratezza non è altissimo per questo modello.","metadata":{}},{"cell_type":"code","source":"evaluator(cross_encoder)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T10:47:39.227338Z","iopub.execute_input":"2023-05-10T10:47:39.228027Z","iopub.status.idle":"2023-05-10T10:47:41.484301Z","shell.execute_reply.started":"2023-05-10T10:47:39.227976Z","shell.execute_reply":"2023-05-10T10:47:41.483233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A cosa servono i Cross-Encoder?\n\nI cross-encoder possono essere usati ogni volta che bisogna classificare coppie di frasi, come detto hanno prestazioni migliori dei Bi-Encoder ma scalano male.\n\nI Bi-Encoder a loro volta possono essere usati per tutti quei task come la ricerca, il clustering, ... comunque quando abbiamo tante frasi da confrontare.\n\nPer dare una misura della poca scalabilità dei cross-encoder si pensi che fare clustering di 10000 frasi potrebbe richiedere il calcolo di 50 milioni combinazioni, circa 65 ore. Lo stesso task il bi-encoder lo risolve in pochi secondi.\n\n### Retrieve & Re-Rank\n\n<br>\n\n![pipeline](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/InformationRetrieval.png)\n\n<br>\n\nI Cross-Encoder sono molto performanti se combinati con i Bi-Encoder, in particolare nella ricerca. Una particolare tecnica che li coinvolge è il [retrieve & re-rank](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) che in poche parole consiste in:\n* **retrieve**: applicare il Bi-Encoder su una vasta base di possibili risultati per fare una *\"scrematura\"*\n\n<br>\n\n![retrieve](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/SemanticSearch.png)\n\n<br>\n\n* **re-rank**: applicare il Cross-Encoder per ordinare un sottoinsieme di risultati e scartare quelli irrilevanti\n\nEsempio, in un dataset di 1 milione di documenti viene applicato un bi-encoder che restituisce 100 risultati per la richiesta effettuata dall'utente, su questi 100 viene applicato il cross-encoder che restituirà i primi 10 in ordine di somiglianza.\n\n<br>\n\n![rerank](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/CrossEncoder.png)\n\n<br>\n\n\n> In SBERT si possono trovare diversi [cross-encoder pre-addestrati](https://www.sbert.net/docs/pretrained_cross-encoders.html)","metadata":{}}]}