{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy\n",
    "\n",
    "## Lavorare su grandi quantità di dati\n",
    "\n",
    "Dopo i primi passi in questa parte verrà usata la libreria su grandi quantità di dati, mostrate le strutture e le potenzialità degli approcci statistico e basato sulle regole e la loro combianzione.\n",
    "\n",
    "<br>\n",
    "\n",
    "![struct](https://spacy.io/images/architecture.svg)\n",
    "\n",
    "<br>\n",
    "\n",
    "### Vocab\n",
    "\n",
    "SpaCy conserva tutti i dati condivisi in un oggetto *Vocab*. Per dati non intendiamo solo le parole ma anche i tag, le entità, gli schemi e le etichette.\n",
    "\n",
    "Il *Vocab* è una tabella di lookup, quando qualcosa viene caricato genera un ID con *codifica hash* così che possa essere usato sia per estrarre ID mediante la parola che la parola mediandte l'ID. Gli ID sono univoci, se qualcosa occorre più volte nei documenti non dovrà essere ricaricato.\n",
    "\n",
    "> N.B. Gli hash ID non sono reversibili, se una stringa non sta nel Vocab non possiamo generarla/caricarla mediante un hash ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee hash from string:  3197928453018144401\n",
      "coffee string from hash:  coffee\n",
      "hash value: 3197928453018144401\n"
     ]
    }
   ],
   "source": [
    "nlp.vocab.strings.add(\"coffee\")\n",
    "\n",
    "coffee_hash = nlp.vocab.strings[\"coffee\"]\n",
    "coffee_string = nlp.vocab.strings[coffee_hash]\n",
    "\n",
    "print(\"coffee hash from string: \", coffee_hash)\n",
    "print(\"coffee string from hash: \", coffee_string)\n",
    "\n",
    "doc = nlp(\"I love coffee\")\n",
    "print(\"hash value:\", doc.vocab.strings[\"coffee\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexemes\n",
    "\n",
    "I *Lexemes* sono voci del vocabolario indipendenti dal contesto, possono contenere informazioni lessicali ma non tag, entità, ... che dipendono dal contesto.\n",
    "\n",
    "<br>\n",
    "\n",
    "![lexeme](https://spacy.io/images/vocab_stringstore.svg)\n",
    "\n",
    "<br>\n",
    "\n",
    "Come si vede nell'immagine un documento contiente token e tutti i loro attributi, questi sono legati al vocabolario che contiene i lessemi, questa tabella di lookup è a sua volta collegata tramite hash ID allo string store.\n",
    "\n",
    "> `is_alpha` nella cella successiva si riferisce a *is alphabetical*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee 3197928453018144401 True\n"
     ]
    }
   ],
   "source": [
    "lexeme = nlp.vocab[\"coffee\"]\n",
    "\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc\n",
    "\n",
    "Il `Doc` è la struttura centrale di SpaCy, viene creato in automatico quando si passa un testo nell'oggetto *nlp* ma può anche essere creato manualmente.\n",
    "\n",
    "Nel prossimo esempio viene creato un `Doc` di tre parole, ogni *token* ha un attributo *spaces* ovvero un booleano che indica se la parola è seguita o no da uno spazio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "words = [\"Hello\", \"world\", \"!\"]\n",
    "spaces = [True, False, False]\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "doc = Doc(nlp.vocab, words, spaces)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo `Span` è una parte del `Doc`, consiste in uno o più token. Per creare uno `Span` bisogna passare come argomenti il `Doc` di riferimento e gli indici del token iniziale e finale che si vogliono inglobare nello span.\n",
    "\n",
    "<br>\n",
    "\n",
    "![span](https://course.spacy.io/span_indices.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "> gli Span possono essere inseriti manualmente dentro le entità del documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "Hello world\n",
      "(Hello world,)\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "span = Span(doc, 0, 2)\n",
    "\n",
    "print(span)\n",
    "\n",
    "span_w_labels = Span(doc, 0, 2, label = \"GREETING\")\n",
    "\n",
    "print(span_w_labels)\n",
    "\n",
    "doc.ents = [span_w_labels]\n",
    "\n",
    "print(doc.ents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alcuni trucchetti per usare al meglio `Doc` e `Span`:\n",
    "\n",
    "* se hai bisogno delle stringhe come output del tuo processo, converti il *doc* il più tardi possibile, potresti perdere delle relazioni interne all'oggetto\n",
    "* usa gli attributi interni agli oggetti (come `token.i` per l'indice del token)\n",
    "* non dimenticare di passarili nel vocabolario condiviso\n",
    "\n",
    "## Word Vectors\n",
    "\n",
    "SpaCy è in grado di confrontare documenti, span e token e dirci quanto sono simili. Infatti questi oggetti hanno un metodo `.similarity`. La similarità è espressa in un range [0,1], dove 1 è uguale (o molto simile).\n",
    "\n",
    "Nel prossimo esempio calcoleremo la similarità tra frasi e la similarità tra parole (token.)\n",
    "\n",
    "> N.B. per applicare la similarità bisogna usare pipeline di SpaCy medie o grandi, quele contrassegnate con il suffisso *_lg* (large) o *_md* (medium). Quella usata in precedenza aveva il suffisso *_sm* (small) e non consente di valutare la similarità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19793302526048495 \t 0.974312099000299\n",
      "0.1790039986371994 \t 0.6850197911262512\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "doc1 = nlp(\"I like pasta\")\n",
    "doc2 = nlp(\"My car is red\")\n",
    "doc3 = nlp(\"I like pizza\")\n",
    "\n",
    "print(doc1.similarity(doc2), \"\\t\", doc1.similarity(doc3))\n",
    "print(doc2[1].similarity(doc3[2]), \"\\t\", doc1[2].similarity(doc3[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precedentemente sono stati confrontati oggetti dello stesso tipo, *doc* e *doc* o *token* e *token* ma possiamo anche confrontare oggetti di tipo diverso come *doc* e *span*, *doc* e *token*, ...\n",
    "\n",
    "Per calcolare la similarità SpaCy utilizza i *word vectors* sono rappresentazioni multidimensionali delle parole tramite vettori, per crearle vengono utilizzati algoritmi come [Word2Vec](https://en.wikipedia.org/wiki/Word2vec), per avere un vettore che rappresenti un documento o uno span SpaCy fa la media dei vettori delle parole contenute, chiaramente questo metodo predilige testi brevi. La misura di similarità che si usa solitamente con i testi è la [distanza del coseno](https://it.wikipedia.org/wiki/Coseno_di_similitudine).\n",
    "\n",
    "<br>\n",
    "\n",
    "![cosine](https://miro.medium.com/v2/resize:fit:720/format:webp/1*GK56xmDIWtNQAD_jnBIt2g.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Il calcolo della similarità può essere molto utile in molte applicazioni (es. rimozione di duplicati), ma quando una frase è \"simile\"? Non esiste una risposta oggettiva perchè dipende dal contesto, ad esempio le frasi *\"Amo i gatti\"* e *\"Odio i gatti\"* possono essere simili perchè si parla di gatti ma completamente opposte allo stesso tempo.\n",
    "\n",
    "Se vogliamo accedere al vettore di un token basta usare il metodo `.vector` (ad esempio il vettore della parola pizza). Come si può vedere i word vector di SpaCy (default) hanno lunghezza 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.20348 , -2.376   , -4.6129  ,  2.5783  ,  0.70192 , -3.9578  ,\n",
       "       -2.7163  ,  1.2299  , -1.1297  ,  3.6804  ,  4.0516  , -0.96515 ,\n",
       "        4.6248  ,  4.0276  ,  0.85267 , -1.823   , -0.16034 ,  2.3589  ,\n",
       "        0.88145 , -1.0626  ,  2.0095  ,  3.7962  , -0.55322 ,  2.0663  ,\n",
       "       -1.8375  ,  2.0172  , -1.1873  ,  1.0524  , -4.7658  ,  0.84146 ,\n",
       "        3.1651  , -0.16254 ,  2.4484  , -0.17522 ,  1.1742  , -1.81    ,\n",
       "        0.3595  ,  1.3136  , -1.0159  ,  0.97661 , -0.98931 ,  1.7808  ,\n",
       "        4.1094  , -0.49558 ,  6.1189  ,  1.5496  , -2.2132  , -3.1217  ,\n",
       "        0.96873 ,  0.92924 , -1.6941  , -4.1219  ,  0.82571 , -3.871   ,\n",
       "       -0.32475 , -2.6923  , -0.52908 ,  2.7431  ,  2.4325  ,  0.24599 ,\n",
       "        5.3924  , -1.6597  ,  1.8607  , -2.1747  ,  5.0726  ,  2.3184  ,\n",
       "       -6.8177  , -0.34929 ,  0.58031 , -0.24007 , -7.3874  ,  1.2737  ,\n",
       "       -0.58188 ,  0.36543 ,  3.5527  , -0.68641 ,  1.7008  , -1.1614  ,\n",
       "        2.077   , -3.0627  , -1.3665  ,  2.8223  ,  3.4451  , -0.04273 ,\n",
       "       -3.0915  , -1.9156  ,  2.364   ,  0.34387 , -1.2458  , -2.8766  ,\n",
       "       -0.05619 ,  3.0037  ,  0.54841 , -1.9131  ,  2.9968  , -3.8113  ,\n",
       "        4.2592  , -1.4645  , -0.88061 , -6.6617  ,  0.90574 , -4.4906  ,\n",
       "       -0.54536 , -3.4635  , -1.1199  , -1.3109  , -6.2477  ,  4.288   ,\n",
       "       -3.1878  ,  0.50264 , -0.25175 ,  0.72972 ,  1.0315  , -1.0715  ,\n",
       "       -1.7338  ,  2.6518  ,  2.3121  , -5.0109  ,  1.708   , -0.15834 ,\n",
       "       -1.5272  , -1.0754  ,  1.3374  ,  4.0308  ,  1.1492  ,  2.2003  ,\n",
       "        4.4051  , -5.4247  ,  0.80199 ,  1.0024  , -1.2388  , -1.7494  ,\n",
       "        2.5012  , -1.5831  ,  0.92959 ,  1.0414  , -2.6936  , -5.3202  ,\n",
       "       -0.46417 , -0.28321 , -0.3219  ,  1.9682  , -1.5362  , -1.1491  ,\n",
       "        1.4374  , -0.84214 , -1.5914  , -0.55626 , -5.9156  , -1.3073  ,\n",
       "       -1.4003  ,  0.089987,  0.90948 , -0.86613 ,  2.4094  , -1.441   ,\n",
       "        5.0864  ,  1.581   , -0.48139 , -3.3359  ,  2.7271  , -4.1121  ,\n",
       "        2.0935  , -1.2408  ,  2.1674  , -2.5646  ,  2.5348  , -2.3718  ,\n",
       "       -0.25307 ,  5.22    , -0.13946 , -2.194   , -2.7516  ,  3.8245  ,\n",
       "       -1.7326  ,  2.3916  ,  0.53653 , -2.4682  ,  5.5811  ,  0.89127 ,\n",
       "       -0.34505 ,  2.6114  ,  0.13358 , -1.4019  , -1.8793  ,  0.24156 ,\n",
       "       -1.8389  , -2.7054  ,  0.39586 ,  2.916   , -4.4504  ,  3.4074  ,\n",
       "       -0.57392 ,  2.2494  ,  1.1783  , -4.9368  ,  0.3025  , -0.75432 ,\n",
       "        1.1682  ,  0.26734 , -0.83147 ,  2.8104  , -1.8849  ,  1.5546  ,\n",
       "        1.2026  ,  1.0157  ,  0.37767 ,  1.3511  ,  0.85411 ,  1.9107  ,\n",
       "        6.1168  , -0.55111 , -0.82052 ,  3.3159  ,  0.008814, -2.3759  ,\n",
       "        0.23584 ,  3.7545  , -2.0224  , -0.038513,  4.0915  , -2.044   ,\n",
       "       -1.6701  ,  2.6134  ,  2.7284  , -3.7848  ,  0.12454 ,  2.3149  ,\n",
       "        0.48716 , -0.11558 , -1.778   , -0.47368 ,  1.256   , -1.4243  ,\n",
       "       -2.9256  ,  1.5813  ,  2.6085  ,  3.4645  , -1.8718  ,  0.9703  ,\n",
       "       -4.457   , -4.8317  ,  1.2261  ,  5.8774  , -0.9663  ,  0.70336 ,\n",
       "        1.5462  ,  1.3874  , -0.93865 ,  0.14287 , -4.9262  ,  1.0487  ,\n",
       "       -5.0987  , -1.4581  , -4.5887  , -1.3069  , -0.56476 ,  5.3789  ,\n",
       "       -2.0097  ,  1.639   ,  5.7196  ,  1.4591  , -5.0024  ,  0.75934 ,\n",
       "       -0.68461 , -1.2137  ,  2.2437  , -1.3987  , -0.039985,  2.8666  ,\n",
       "        0.11198 , -0.31523 ,  0.13079 , -0.7025  ,  1.3822  , -7.028   ,\n",
       "       -0.32506 ,  4.7684  , -2.8591  , -0.18918 , -0.01855 , -0.69972 ,\n",
       "       -4.0972  , -1.5531  , -3.0333  , -0.48156 ,  1.8798  , -2.3428  ,\n",
       "       -5.0014  ,  1.3688  ,  1.3119  , -1.5409  ,  1.3823  , -3.275   ,\n",
       "       -2.4584  , -2.0094  , -2.4621  ,  3.3805  ,  2.3166  ,  0.076361],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(doc3[2].vector.shape)\n",
    "doc3[2].vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinare modelli statistici e regole\n",
    "\n",
    "Combinare i due approcci del NLP è un attrezzo potente, vedremo come fare con SpaCy.\n",
    "\n",
    "L'**approccio statistico** è utile quando c'è bisogno di generalizzare e abbiamo esempi su cui applicare/addestrare i modelli, ad esempio la NER è un task che và risolto con l'approccio statistico.\n",
    "\n",
    "L'**approccio basato su regole** è utile quando bisogna mappare un numero finito di istanze, ad esempio gli alimenti che non può mangiare un intollerante al lattosio in un libro di ricette.\n",
    "\n",
    "### PhraseMatcher\n",
    "\n",
    "Il PhraseMatcher è un'evoluzione del classico matcher, ci consente di fare anche ricerca per keywords. Molto veloce ci dà un accesso diretto ai token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n",
      "Root token: Retriever\n",
      "Root head token: have\n",
      "Previous token: a DET\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "pattern = nlp(\"Golden Retriever\")\n",
    "matcher.add(\"DOG\", [pattern])\n",
    "doc = nlp(\"I have a Golden Retriever\")\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matcher(doc):\n",
    "    # Get the matched span\n",
    "    span = doc[start:end]\n",
    "    print(\"Matched span:\", span.text)\n",
    "     # Get the span's root token and root head token\n",
    "    print(\"Root token:\", span.root.text)\n",
    "    print(\"Root head token:\", span.root.head.text)\n",
    "    # Get the previous token and its POS tag\n",
    "    print(\"Previous token:\", doc[start - 1].text, doc[start - 1].pos_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7311948a7550bce7c0db859b04b0f1855317afbfa5ee8d2f1ff81230a0dc77ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
