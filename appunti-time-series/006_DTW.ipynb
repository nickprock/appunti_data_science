{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Time Warping\n",
    "\n",
    "![DTW](https://databricks.com/wp-content/uploads/2019/04/Euclidean_vs_DTW.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "[Image Credits](https://databricks.com/blog/2019/04/30/understanding-dynamic-time-warping.html)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Definizione\n",
    "\n",
    "**Dynamic Time Warping** (DTW) è un algoritmo utilizzato per misurare la similarità tra due o più serie temporali, andando a leggere su [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_time_warping) troviamo la seguente definizione:\n",
    "\n",
    "> *\"Il Dynamic time warping, o DTW, è un algoritmo che permette l'allineamento tra due sequenze, e che può portare ad una misura di distanza tra le due sequenze allineate. Tale algoritmo è particolarmente utile per trattare sequenze in cui singole componenti hanno caratteristiche che variano nel tempo, e per le quali la semplice espansione o compressione lineare delle due sequenze non porta risultati soddisfacenti.\"*\n",
    "\n",
    "Che casi d'uso ci suggerisce la definizione? Prendiamo ad esempio il riconoscimento vocale, una persona potrebbe parlare più velocemente o più lentamente della voce campione preregistrata, il DTW non risente di questo problema a differenza di una distanza che venga applicata \"punto per punto\".\n",
    "\n",
    "Il DTW è molto utilizzato in ambito *IoT* dove gli stream di dati proveninenti da video, audio, sensori, possono essere trasformati in una sequenza lineare per essere analizzati con questa tecnica, in particolare è molto efficace con serie ad alta frequenza di campionamento, pensiamo ad esempio al mercato delle utilities o dell'automotive.\n",
    "\n",
    "L'idea di base è calcolare la distanza tra due vettori/serie storiche **indipendentemente dalla loro lunghezza** e per farlo bisogna che i vettori rispettino le seguenti regole:\n",
    "* ogni indice della prima sequenza deve poter essere confrontato con tutti gli indici delle altre e viceversa\n",
    "* il primo indice della prima sequenza deve essere associato al primo indice dell'altra sequenza (ma non deve essere la sua unica corrispondenza)\n",
    "* l'ultimo indice della prima sequenza deve corrispondere all'ultimo indice dell'altra sequenza (ma non deve essere la sua unica corrispondenza)\n",
    "\n",
    "## Algoritmo\n",
    "\n",
    "> Per illustrare il DTW userò in parte un breve esempio con due sequenze di pochi elementi preso da [riptutorial](https://riptutorial.com/it/algorithm/example/24981/introduzione-al-dynamic-time-warping).\n",
    "\n",
    "L'algoritmo di base è molto semplice, vedremo la differenza della similarità tra serie con DTW e distanza euclidea, partiamo creando gli array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "serie_1 = np.array([1, 2, 3, 5, 5, 5, 6], ndmin = 2)\n",
    "serie_2 = np.array([1, 1, 2, 2, 3, 5], ndmin =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_2New = serie_2.copy()\n",
    "serie_2New = np.append(serie_2New, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le due serie hanno lunghezza diversa quindi un confronto punto per punto con distanza euclidea (o altra distanza) non sarebbe del tutto corretto. Supponiamo che le due serie partano nello stesso periodo e che la serie_2 finisca prima, quindi aggiungiamo un elemento per calcolare la distanza (*non rispetta le regole sugli indici del DTW*).\n",
    "\n",
    "\n",
    "$$  d\\left( p,q\\right)   = \\sqrt {\\sum _{i=1}^{n}  \\left( q_{i}-p_{i}\\right)^2 } $$\n",
    "\n",
    "La distanza calcolata è 7.14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt(np.sum((serie_1-serie_2New)**2))\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora al calcolo della distanza mediante DTW, per farlo ci servirà una matrice di dimensione *n x m* dove *m* ed *n* sono la lunghezza della serie più 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = serie_1.shape[1]+ 1\n",
    "m = serie_2.shape[1]+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW = np.zeros([n,m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il primo elemento della matrice *DTW[0,0]* deve essere pari a 0, mentre prima riga e prima colonna pari ad infinito. Quanto fatto serve per il ***cold start*** dell'algoritmo. \n",
    "Il cold start è il confronto con i periodi precedenti quando si è al primo passo dell'algoritmo, impostando una riga fittizia ad infinito non si incorre in situazioni anomale e si evita di implementare condizioni sullo start che appesantirebbero ulteriormente il calcolo.\n",
    "> ecco spiegato perchè la dimensione della serie più 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTW[0,1:] = np.inf\n",
    "DTW[1:,0] = np.inf\n",
    "print(DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ogni posizione della matrice verrà calcolata la distanza euclidea di ogni punto di una serie da tutti i punti delle altre partendo dalla posizione *DTW[1,1]*. Ad ogni distanza viene aggiunto il minimo tra:\n",
    "* il valore precedente sulle righe: **cancellazione**\n",
    "* il valore precedente sulle colonne: **inserimento**\n",
    "* il valore precedente in diagonale: **corrispondenza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,n):\n",
    "    for j in range(1, m):\n",
    "        dist = abs(serie_1[:,i-1] - serie_2[:,j-1]) \n",
    "        DTW[i,j] = dist + min([DTW[i-1,j], DTW[i,j-1], DTW[i-1,j-1]])\n",
    "\n",
    "print(DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algoritmo restituisce una matrice con tutte le posizioni valorizzate.\n",
    "Arrivati a questo punto partendo da *DTW[0,0]* bisogna costruire un percorso che tocchi il valore minimo più vicino a quello nella posizione in cui ci troviamo muovendoci da sinistra verso destra in orizzontale/verticale/obliquo, questo è il **Warping Path**.\n",
    "\n",
    "* uno spostamento orizzontale significa che *serie_2* è accelerata durante questo intervallo.\n",
    "* uno spostamento verticale significa che *serie_2* è decelerata durante questo intervallo.\n",
    "* una mossa diagonale significa che durante questo periodo le serie camminano di pari passo\n",
    "\n",
    "**Il valore finale del path è la distanza tra le serie.**\n",
    "Dalla matrice si nota che il calcolo non è stato influenzato dalla diversa dimensione delle sequenze e che il valore finale è molto più piccolo di quello calcolato punto per punto con la distanza euclidea.\n",
    "\n",
    "<br>\n",
    "\n",
    "![matrice2](https://i.imgur.com/OqkHF5t.png)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window Constraint\n",
    "\n",
    "La complessità di calcolo del DTW è ***O(m * n)*** dove *m* e *n* rappresentano la lunghezza di ciascuna sequenza quindi se avessimo sequenze molto lunghe il confronto tra le due risulterebbe complesso, ed anche inutile, perchè alcuni confronti verrebbero effettuati su posizioni lontanissime.\n",
    "Prendiamo l'esempio della serie storica, vorrebbe dire confrontare periodi molto distanti temporalmente che non hanno nessuna relazione ed influenza tra loro.\n",
    "Per questo motivo viene inserita un parametro *w*, una **finestra temporale** su cui calcolare le differenze.\n",
    "\n",
    "La finestra temporale è il valore minimo tra un intero definito dall'utente (io ho utilizzato 1) e la differenza in valore assoluto tra *m* ed *n*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = max([1, abs(n-m)])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito come cambia l'algoritmo per il calcolo della distanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,n):\n",
    "    for j in range(max([1,i-w]), min([m, i+w])):\n",
    "        dist = abs(serie_1[:,i-1] - serie_2[:,j-1]) \n",
    "        DTW[i,j] = dist + min([DTW[i-1,j], DTW[i,j-1], DTW[i-1,j-1]])\n",
    "\n",
    "print(DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esempio proposto non si noteranno differenze viste le sequenze molto corte e con una differenza di una sola posizione, ma per sequenze molto lunghe e con differenze di lunghezza evidenti l'impatto è tangibile.\n",
    "\n",
    "### Miglioramenti al DTW\n",
    "\n",
    "Vista la complessità quadratica del DTW sono stati proposti alcuni migliorameti dell'algoritmo, il più conosciuto è probabilmente il [FastDTW](https://www.semanticscholar.org/paper/FastDTW%3A-Toward-Accurate-Dynamic-Time-Warping-in-Salvador-Chan/05a20cde15e172fc82f32774dd0cf4fe5827cad2).\n",
    "Il FastDTW cerca di migliorare le performance approssimando alcuni risultati, non sempre questa riduzione di tempi si traduce in una qualità del risultato accettabile.\n",
    "Ci sono molti paper e package su questo algoritmo, vi lascio il link della libreria python [fastdtw](https://pypi.org/project/fastdtw/) e il paper [*\"FastDTW is approximate and Generally Slower than the Algorithm it Approximates\"*](https://arxiv.org/abs/2003.11246) che spiega in quali casi questo algoritmo sia davvero più performante (mantenendo accettabile l'efficacia) del DTW classico.\n",
    "\n",
    "## DTW e Machine Learning\n",
    "\n",
    "Tornando a quanto detto nell'introduzione, come può essere/viene usato il DTW nei problemi di Machine Learning?\n",
    "\n",
    "* **apprendimento supervisionato**, come distanza per algoritmi KNN su Time Series\n",
    "* **apprendimento non supervisionato**, come misura di similarità nel clustering di Time Series\n",
    "* **apprendimento semi-supervisionato**, etichettare le Time Series utilizzando un algoritmo di clustering basato su DTW e successivamente classificare secondo queste assegnazioni\n",
    "\n",
    "Di seguito un esempio di clustering basato sul DTW.\n",
    "\n",
    "<br>\n",
    "\n",
    "![clustering](https://i.imgur.com/9WK5DXr.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Ingrandendo il grafico finale si può notare come alcune serie dei cluster B e C sembrino molto più vicine al centroide A in alcuni periodi ma il DTW non ne risente e permette un raggruppamento migliore.\n",
    "\n",
    "<br>\n",
    "\n",
    "![dettaglio](https://i.imgur.com/sbwJBX6.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Lascio alcuni paper del 2020 sull'argomento per chi volesse approfondire:\n",
    "\n",
    "* [Time Series Clustering Model Based on DTW for Classifying Car Parks](https://www.mdpi.com/1999-4893/13/3/57)\n",
    "* [Intertemporal Similarity of Economic Time Series: An Application of Dynamic Time Warping](https://link.springer.com/content/pdf/10.1007/s10614-020-09986-0.pdf)\n",
    "* [Time series classification using local distance-based features in multi-modal fusion networks](https://www.sciencedirect.com/science/article/pii/S0031320319303279)\n",
    "* [DTW-NN: A novel neural network for time series recognition using dynamic alignment between inputs and weights](https://www.sciencedirect.com/science/article/abs/pii/S0950705119303995)\n",
    "* [Adaptively constrained dynamic time warping for time series classification and clustering](https://www.sciencedirect.com/science/article/pii/S0020025520303054)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
