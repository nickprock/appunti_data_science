{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "\n",
    "Trovare i valori anomali nei dati è un processo molto delicato perchè presuppone la conoscenza del fenomeno che si và ad osservare.\n",
    "<br>\n",
    "**Che cos'è un outlier?** In maniera più semplice possibile *un outlier è un'osservazione che differisce significativamente dalle altre della stessa variabile*.\n",
    "Esistono molti tipi di outlier ad esempio:\n",
    "* molte più visite ad un sito per un breve periodo di tempo: **outlier additivo**\n",
    "* i server del sito vanno offline e non ricevete visite: **cambiamento temporale**\n",
    "<br>\n",
    "\n",
    "Nelle serie storiche questa differenza deve essere ancora più marcata perchè deve differire dai pattern comportamentali della serie, utilizzando sempre Airpassenger, abbiamo già visto che ha un trend crescente con componente stagionale ad effetto moltiplicativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airpassengers = pd.read_csv(\"airpassenger.csv\")\n",
    "airpassengers.columns = [\"Time\",\"Passengers\"]\n",
    "#airpassengers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(airpassengers.shape[0]), airpassengers[\"Passengers\"].values, color='tab:blue')\n",
    "plt.gca().set(title=\"Airpassengers\", xlabel=\"Time\", ylabel=\"Passengers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso non possiamo affermare che l'osservazione 140 è un outlier solo perchè è nettamente maggiore della 15, perchè segue il trend della serie. Allo stesso modo **i picchi non possono essere considerati outlier perchè effetto della stagionalità.**\n",
    "<br>\n",
    "Introduciamo artificialmente degli outlier in airpassenger:\n",
    "* creare un vettore di 10 interi in maniera completamente casuale\n",
    "* sostituire nelle 10 posizioni un valore molto alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, airpassengers.shape[0], 10)\n",
    "airpassengers.iloc[idx,1] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(airpassengers.shape[0]), airpassengers[\"Passengers\"].values, color='tab:blue')\n",
    "plt.gca().set(title=\"Airpassengers with outlier\", xlabel=\"Time\", ylabel=\"Passengers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo notebook vedremo **alcuni** metodi per trattare i valori anomali nelle serie storiche univariate.\n",
    "<br>\n",
    "L'analisi statistica delle serie storiche fornisce già molte tecniche, se si aggiungono quelle di ML/DL questo notebook potrebbe diventare infinito.\n",
    "<br>\n",
    "***N.B. In coda troverete alcuni link che potrebbero essere interessanti***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposizione della serie e analisi dei residui\n",
    "La prima tecnica è scomporre la serie nelle sue componenti principali e studiarne i residui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "seas = seasonal_decompose(airpassengers.Passengers, model = 'multiplicative', freq=12).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo subito notare che, guardando i residui si possono facilmente individuare gli outlier.\n",
    "<br>\n",
    "Ora andrebbero condotti dei test, solitamente il t-student test, per verificare se sono davvero solo questi gli outlier della serie, o se queste valli non sono outlier. Questa tecnica è abbastanza semplice ma anche molto rigida quindi se la  serie deriva da un fenomeno molto erratico può indurre in valutazioni non corrette. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection utilizzando la distribuzione Gaussiana\n",
    "Questa tecnica è molto utilizzata ed insegnata ma presuppone che i dati si distribuiscano come una gaussiana (indipendente, identicamente distribuita), cosa che non succede spesso nella realtà, quindi la tralascerò ma nei link utili trovate un articolo (con codice) per testare l'approccio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine SVM\n",
    "Le SVM sono solitamente associate alla classificazione, in particolare alla classificazione binaria ma possono essere utilizzate per trovare gli outlier, in particolare sono state utilizzate nella **novelty detection**.\n",
    "<br>\n",
    "Il loro funzionamento in questo campo è semplice, trovano una funzione che positiva nelle regioni con alta densità di punti e negativa dove c'è bassa densità, quindi anomalie.\n",
    "<br>\n",
    "Prima di applicare l'algoritmo applichiamo una traformazione scalando i valori tra [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler((-1,1))\n",
    "scaled_data = scaler.fit_transform(airpassengers[[\"Passengers\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(airpassengers.shape[0]), scaled_data, color='tab:blue')\n",
    "plt.gca().set(title=\"Airpassengers Scaled\", xlabel=\"Time\", ylabel=\"Passengers - Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo OneClassSVM e impostiamo due parametri:\n",
    "* *nu* come la percentuale di outlier da cercare, io ne ho inseriti 10 su circa 140 osservazioni e quindi inserisco il 10%\n",
    "* gamma è il coefficiente della funzione Kernel utilizzata dalla SVM, in questo caso avendo una serie univariata sarebbe:\n",
    "    * 1 = 1/n_features col metodo *auto*\n",
    "    * 1/(n_features * varianza(serie)) col metodo *scale*\n",
    "<br>\n",
    "\n",
    "Questo metodo crea un vettore che è:\n",
    "* 1 se il dato è conforme alla distribuzione osservata\n",
    "* -1 valore anomalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "model = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"scale\")\n",
    "model.fit(scaled_data)\n",
    "df = pd.DataFrame(scaled_data, columns=[\"Scaled Data\"])\n",
    "df[\"anomalySVM\"] = pd.Series(model.predict(scaled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "a = df.loc[df['anomalySVM'] == -1, ['Scaled Data']] #anomaly\n",
    "\n",
    "ax.plot(range(df.shape[0]), df['Scaled Data'], color='blue')\n",
    "ax.scatter(a.index,a['Scaled Data'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algoritmo trova più valori anomali di quanti ne avevamo indotti, normale avendo sovrastimato la percentuale. Questo algoritmo usa una funzione che crea bordi molto regolari per dividere racchiedere gli outlier, potrebbe essere un problema.\n",
    "<br>\n",
    "**N.B. Nei link utili anche uno sulla comparazione di diverse tecniche dove la rappresentazione grafica aiuta a capire meglio il problema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest\n",
    "Isolation Forest calssifica le anomalie semplicemente utilizzando il fatto che queste sono estremamente differenti dagli altri valori, quindi costruisce degli alberi di classificazione e se il path di classifcazione di questi punti è significativamente più breve degli altri sono anomalie.\n",
    "<br>\n",
    "**[ATTENZIONE!!! Spiegazione fortemente semplicistica]**\n",
    "\n",
    "<br>\n",
    "\n",
    "Utilizziamo sempre il 10% come soglia, questa volta il parametro è *contamination* nella documentazione troviamo i bound del parametro, valore massimo 0.5, se supera il 50% non è più un'anomalia. Il parametro *behavior* è deprecato nella nuova versione 0.22 si scikit-learn ma verrà rimosso solo nella 0.24, quindi per non avere warning lo impostiamo a new come chiede la documentazione. **[leggere la documetazione fa risparmiare molto tempo]**\n",
    "<br>\n",
    "Anche in questo caso viene restituito i un vettore di -1 *anomalia*, 1 *valore standard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isoF = IsolationForest(contamination=0.1, behaviour=\"new\")\n",
    "isoF.fit(scaled_data)\n",
    "df[\"anomalyIsoF\"] = pd.Series(isoF.predict(scaled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "a = df.loc[df['anomalyIsoF'] == -1, ['Scaled Data']]\n",
    "\n",
    "ax.plot(range(df.shape[0]), df['Scaled Data'], color='blue')\n",
    "ax.scatter(a.index,a['Scaled Data'], color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche in questo caso trova più valori di quelli indotti ma almeno le osservazioni artificiali vengono segnalate.\n",
    "<br>\n",
    "Questa volta i nostri esperimenti non hanno avuto grande successo, in parte è dovuto alle poche osservazioni del dataset che si confà più a tecniche di statistica classica come lo studio dei residui piuttosto che al ML.\n",
    "<br>\n",
    "**N.B. ad ogni rilancio dell'intero notebook i vostri valori anomali cambierianno quindi potreste trovare commenti disallineati con il risultato del vostro esperimento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendice: Novelty vs Anomaly Detection\n",
    "La differenza principale tra le due analisi è:\n",
    "* in Anomaly Detection viene passato in fase di train un dataset contenente anche outlier e il modello li classifica come tali\n",
    "* in Novelty Detection il dataset di train è privo di outlier e quindi in fase di test trova i valori che si discostano da qunto osservato prima\n",
    "\n",
    "<br>\n",
    "\n",
    "### Link Utili\n",
    "* [Comparing anomaly detection algorithms for outlier detection on toy datasets](https://scikit-learn.org/stable/auto_examples/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py)\n",
    "* [Time Series Anomaly Detection Algorithms](https://blog.statsbot.co/time-series-anomaly-detection-algorithms-1cef5519aef2)\n",
    "* [Outlier detection with time-series data mining](https://www.datasciencecentral.com/profiles/blogs/outlier-detection-with-time-series-data-mining)\n",
    "* [Time Series of Price Anomaly Detection](https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
