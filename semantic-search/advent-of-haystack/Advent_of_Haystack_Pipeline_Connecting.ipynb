{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickprock/appunti_data_science/blob/master/semantic-search/advent-of-haystack/Advent_of_Haystack_Pipeline_Connecting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advent of Haystack: Day 1\n",
        "_Make a copy of this Colab to start!_\n",
        "\n",
        "In this first challenge, we are going to build a RAG pipeline that answers questions based on the contents of a URL. Most of the pipeline is ready, but your task is to complete the pipeline connections 👇\n",
        "\n",
        "You should complete Step 5 of this colab.\n",
        "\n",
        "### Components to use:\n",
        "1. `LinkContentFetcher`: Expects a list of URLs and returns `ByteStream` type\n",
        "2. `HTMLToDocument`: Expects a `ByteStream` and creates `Document` type.\n",
        "3. `DocumentSplitter`: This expcects a list of `Documents` and returns a list of split, preprocessed documents.\n",
        "4. `PromptBuilder`: To define the manner we want to interact with an LLM. We use Jinja templating\n",
        "5. `GPTGenereator`: Expects a fully formed prompt and queries an OpenAI GPT model."
      ],
      "metadata": {
        "id": "5q2FHwPY-wqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Installation\n",
        "\n",
        "**Note:** There is a known issue with colab due to a version conflict error related to `llmx` which comes with Colab. You might get an `llmx` error. You can safely ignore this, or run `pip uninstall -y llmx`"
      ],
      "metadata": {
        "id": "ZALZDx-LFebK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJJ5AT3Z79e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cc006c-6bea-4edf-d903-e7f91d02dfab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.0.0b1-py3-none-any.whl (185 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/185.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/185.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.4/185.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.2)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.2.1)\n",
            "Collecting openai<1.0.0 (from haystack-ai)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.5.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Collecting rank-bm25 (from haystack-ai)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (2.31.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (3.9.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (4.0.3)\n",
            "Installing collected packages: monotonic, rank-bm25, lazy-imports, backoff, posthog, openai, haystack-ai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 haystack-ai-2.0.0b1 lazy-imports-0.3.1 monotonic-1.6 openai-0.28.1 posthog-3.1.0 rank-bm25-0.2.2\n",
            "Collecting boilerpy3\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: boilerpy3\n",
            "Successfully installed boilerpy3-1.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install haystack-ai\n",
        "!pip install boilerpy3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Enter API keys for LLM and search providers\n",
        "Run this code and you’ll be prompted to enter your OpenAI API Key. If you don’t have a key, [follow these instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key)."
      ],
      "metadata": {
        "id": "W3jwS4A_FmEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Enter OpenAI API key:\")"
      ],
      "metadata": {
        "id": "zy4xBS6v8n1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "dc743680-c695-470f-a3da-aa1625069c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d261bb9b20cc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mopenai_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter OpenAI API key:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    832\u001b[0m             warnings.warn(\"The `stream` parameter of `getpass.getpass` will have no effect when using ipykernel\",\n\u001b[1;32m    833\u001b[0m                     UserWarning, stacklevel=2)\n\u001b[0;32m--> 834\u001b[0;31m         return self._input_request(prompt,\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Create components"
      ],
      "metadata": {
        "id": "85pAAbaPFtZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.generators import GPTGenerator\n",
        "\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = HTMLToDocument()\n",
        "splitter = DocumentSplitter(split_length=100, split_overlap=5)"
      ],
      "metadata": {
        "id": "oXMwKWzUAEaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Given the information below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            Question: {{ query }}. \\n Answer:\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template = template)"
      ],
      "metadata": {
        "id": "qI4OaTHBa-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GPTGenerator(api_key = openai_api_key, model_name = \"gpt-4\")"
      ],
      "metadata": {
        "id": "98SZvedobVKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Add them to a Haystack 2.0 Pipeline"
      ],
      "metadata": {
        "id": "jnDhrfD5AayG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component(name=\"fetcher\", instance=fetcher)\n",
        "pipeline.add_component(name=\"converter\", instance=converter)\n",
        "pipeline.add_component(name=\"splitter\", instance=splitter)\n",
        "pipeline.add_component(name=\"prompt_builder\", instance=prompt_builder)\n",
        "pipeline.add_component(name=\"llm\", instance=llm)"
      ],
      "metadata": {
        "id": "UIXUQWG5AYg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5) Connect the components\n",
        "\n",
        "Complete the pipelne connections to achieve a working pipeline that can be run\n",
        "\n",
        "**PSA:** If you are re-running this cell multiple times and you get a `PipelineConnectionError`, try restarting your Colab runtime."
      ],
      "metadata": {
        "id": "KFQOOQkaAeRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.connect(\"fetcher\", \"converter\")\n",
        "pipeline.connect(\"converter\", \"splitter\")\n",
        "pipeline.connect(\"splitter\", \"prompt_builder\")\n",
        "pipeline.connect(\"prompt_builder\", \"llm\")"
      ],
      "metadata": {
        "id": "hpDVUIhlAi0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a256cb67-0b4d-4625-e207-df252c9764cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e5f9e2e2c68d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fetcher\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"converter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"splitter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"splitter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prompt_builder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_builder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"llm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6) Run the Pipeline"
      ],
      "metadata": {
        "id": "Y2v6GZs6Am5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_dict ={\n",
        "    \"urls\": [\"https://haystack.deepset.ai/blog/customizing-rag-to-summarize-hacker-news-posts-with-haystack2\"],\n",
        "    \"query\": \"How do you build a custom component?\"\n",
        "}\n",
        "\n",
        "\n",
        "result = pipeline.run(data={\"fetcher\": {\"urls\": query_dict[\"urls\"]}, \"prompt_builder\": {\"query\": query_dict[\"query\"]}})"
      ],
      "metadata": {
        "id": "Gbo1QwM9Ambj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['llm']['replies'][0])"
      ],
      "metadata": {
        "id": "daLZtg3gb7m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78775c4a-f695-4555-d170-1082de5758fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Haystack 2.0, a class can become a component with just two additions:\n",
            "\n",
            "1. A @component decorator on the class declaration.\n",
            "2. A run function with a decorator @component.output_types(my_output_name=my_output_type) that describes what output the pipeline should expect from this component.\n",
            "\n",
            "Here's a simple example of a custom component \n",
            "\n",
            "```python\n",
            "from haystack import component \n",
            "\n",
            "@component \n",
            "class HackernewsNewestFetcher(): \n",
            "    @component.output_types(articles=str) \n",
            "    def run(self): \n",
            "        return {'articles': 'Hello world!'}\n",
            "```\n",
            "\n",
            "In this example, the custom component is named 'HackernewsNewestFetcher' and its run function returns a dictionary containing a single key 'articles' with the value 'Hello world!'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7) Draw the Pipeline 🎨\n",
        "When you run this code block, it will create a new file that will appear in the \"Files\" section of Colab (see menu tab on the side)."
      ],
      "metadata": {
        "id": "z0eEFSDYAjOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.draw(\"/content/pipeline.png\")"
      ],
      "metadata": {
        "id": "ctE6bDESAqv8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "3a8c2441-83e2-453b-b7d7-84112b94f08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9879a44d0c48>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/pipeline.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    }
  ]
}