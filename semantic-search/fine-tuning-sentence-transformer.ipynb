{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sentence Transformers\n","\n","In questo notebook faccio fine-tuning di un [Sentence Transformer](https://arxiv.org/abs/1908.10084) per l'italiano!\n","\n","<br>\n","\n","![cover](https://huggingface.co/blog/assets/95_training_st_models/training_process.png)\n","\n","<br>\n","\n","> Questo notebook è basato sul blogpost [How to train sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers).\n","\n","### Cos'è un Sentence-Transformers?\n","\n","Un Sentence-Transformers mappa un testo in un embedding di dimensione fissa che ne rappresenta il significato.\n","\n","### Come funziona?\n","\n","Il Sentence-Transformers non è altro che un modello Transformer, di quelli che possiamo scaricare liberamente da HuggingFace al quale viene aggiunto un livello di pooling per dare una dimensione fissa ai vettori in uscita, di solito si usa il *mean pooling*.\n","\n","Per alcuni task (es. clustering) a volte viene aggiunto anche un livello di *Normalization* alla fine ma non è il focus di questo notebook.\n","\n","## Come fare fine-tuning di un Sentence Tansformers\n","\n","Per addestrare o fare fine tuning di un sentence transformer le prime due cose da conoscere sono:\n","* la disponibilità dei dati e la struttura del dataset di addestramento\n","* le loss function e la loro relazione con la struttura del dataset\n","\n","In questo notebook verrà creato un sentence-transformers per l'italiano che alla fine è stato caricato su [Huggingface](https://huggingface.co)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:55:04.044604Z","iopub.status.busy":"2023-04-21T19:55:04.044150Z","iopub.status.idle":"2023-04-21T19:55:19.197667Z","shell.execute_reply":"2023-04-21T19:55:19.196441Z","shell.execute_reply.started":"2023-04-21T19:55:04.044568Z"},"trusted":true},"outputs":[],"source":["!pip install -U sentence-transformers"]},{"cell_type":"markdown","metadata":{},"source":["## Scelta del modello\n","\n","La prima cosa da fare è sceglieri il modello adatto al proprio obiettivo, il nostro è costruire un modello per l'italiano, possiamo farlo in due modi:\n","1. Prendere un Transformers monolingua già addestrato per il [fill-mask](https://huggingface.co/tasks/fill-mask)\n","2. Prendere un multilingua\n","\n","Ho optato per la prima scelta anche se i checkpoint HuggingFace per il fill-mask in italiano sono molto pochi, nelle prossime celle andremo a costruire il Sentence-Transformers sfruttando [l'omonima libreria](https://www.sbert.net/)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:55:19.200398Z","iopub.status.busy":"2023-04-21T19:55:19.200006Z","iopub.status.idle":"2023-04-21T19:55:32.574713Z","shell.execute_reply":"2023-04-21T19:55:32.572278Z","shell.execute_reply.started":"2023-04-21T19:55:19.200360Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, models\n","\n","model_checkpoint = \"dbmdz/bert-base-italian-uncased\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:55:32.577412Z","iopub.status.busy":"2023-04-21T19:55:32.576570Z","iopub.status.idle":"2023-04-21T19:56:00.957438Z","shell.execute_reply":"2023-04-21T19:56:00.955945Z","shell.execute_reply.started":"2023-04-21T19:55:32.577370Z"},"trusted":true},"outputs":[],"source":["word_embedding_model = models.Transformer(model_name_or_path=model_checkpoint)\n","pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n","#normalize_model = models.Normalize()\n","\n","model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:00.961350Z","iopub.status.busy":"2023-04-21T19:56:00.960983Z","iopub.status.idle":"2023-04-21T19:56:00.971309Z","shell.execute_reply":"2023-04-21T19:56:00.969872Z","shell.execute_reply.started":"2023-04-21T19:56:00.961313Z"},"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"markdown","metadata":{},"source":["#### Perchè non usiamo direttamente un modello come BERT?\n","\n","* Usare un sentence transofrmers al posto del transformers di base abbassa i **tempi di elaborazione**. Ad esempio [fare ricerca su 10000 frasi può richedere circa 65 ore con BERT e 5 secondi con Sentence Transformers](https://arxiv.org/abs/1908.10084).\n","\n","* I Transformers **creano rappresentazioni scarse**, a livello (o anche sotto) di algoritmi più datati come [GloVe](https://nlp.stanford.edu/projects/glove/).\n","\n","<br>\n","\n","![sbert](https://www.sbert.net/_static/logo.png)\n","\n","<br>"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare dataset\n","\n","I Sentence Transformers vengono utilizzati per calcolare la similarità tra frasi, quindi il dataset di train deve essere strutturato in modo da far capire al modello quali sono le frasi simili e quanto lo sono. Esistono diverse strutture di dataset per questo task.\n","\n","1. Le coppie di frasi hanno una label (*int* o *float*) che indica il grado di similarità\n","2. Coppie di frasi simili senza etichetta. Ad esempio: testo->riassunto, domande uguali formulate in modo diverso, testo->traduzione, ...\n","3. La frase ha una label intera che ne rappresenta il tipo. Il dataset viene formato da triplette *[anchor, positive, negative]* dove le prime due hanno la stessa label.\n","4. Triplette *[anchor, positive, negative]* ma senza label\n","\n","In questo caso ho usato il dataset del primo tipo utilizzando la traduzione in italiano di [STSbenchmark dataset](https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark).\n","\n","> N.B. I casi 1 e 3 sono i più semplici su cui lavorare, il più complesso è il 4."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:00.973377Z","iopub.status.busy":"2023-04-21T19:56:00.972972Z","iopub.status.idle":"2023-04-21T19:56:12.582777Z","shell.execute_reply":"2023-04-21T19:56:12.581099Z","shell.execute_reply.started":"2023-04-21T19:56:00.973338Z"},"trusted":true},"outputs":[],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:12.585447Z","iopub.status.busy":"2023-04-21T19:56:12.585028Z","iopub.status.idle":"2023-04-21T19:56:12.991761Z","shell.execute_reply":"2023-04-21T19:56:12.990496Z","shell.execute_reply.started":"2023-04-21T19:56:12.585409Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:12.994909Z","iopub.status.busy":"2023-04-21T19:56:12.993317Z","iopub.status.idle":"2023-04-21T19:56:19.082499Z","shell.execute_reply":"2023-04-21T19:56:19.080866Z","shell.execute_reply.started":"2023-04-21T19:56:12.994868Z"},"trusted":true},"outputs":[],"source":["dataset_train = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"train\")\n","dataset_test = load_dataset(\"stsb_multi_mt\", name=\"it\", split=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:19.084807Z","iopub.status.busy":"2023-04-21T19:56:19.084075Z","iopub.status.idle":"2023-04-21T19:56:19.091955Z","shell.execute_reply":"2023-04-21T19:56:19.090524Z","shell.execute_reply.started":"2023-04-21T19:56:19.084761Z"},"trusted":true},"outputs":[],"source":["print(\"train size: \", dataset_train.shape, \"\\n\", \"test size: \", dataset_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Train\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T19:56:19.094343Z","iopub.status.busy":"2023-04-21T19:56:19.093931Z","iopub.status.idle":"2023-04-21T19:56:19.111277Z","shell.execute_reply":"2023-04-21T19:56:19.109529Z","shell.execute_reply.started":"2023-04-21T19:56:19.094303Z"},"trusted":true},"outputs":[],"source":["dataset_train[:3]"]},{"cell_type":"markdown","metadata":{},"source":["Come possiamo vedere la similarity score và da 0 a 5, per il fine tuning del modello dobbiamo portarla tra 0 e 1.\n","\n","Bisogna creare una struttura ([sentence1, sentence2], label) usando l'oggetto [InputExample](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/readers/InputExample.py). Il risultato di questo passaggio viene usato come input del DataLoader."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:04:02.253370Z","iopub.status.busy":"2023-04-21T20:04:02.251579Z","iopub.status.idle":"2023-04-21T20:04:02.669964Z","shell.execute_reply":"2023-04-21T20:04:02.668452Z","shell.execute_reply.started":"2023-04-21T20:04:02.253295Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import InputExample\n","\n","train_examples = []\n","\n","for i in range(dataset_train.shape[0]):\n","  example = dataset_train[i]\n","  train_examples.append(InputExample(texts=[example['sentence1'], example['sentence2']], label = float(example['similarity_score'])/5.0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:04:11.490629Z","iopub.status.busy":"2023-04-21T20:04:11.490110Z","iopub.status.idle":"2023-04-21T20:04:11.497839Z","shell.execute_reply":"2023-04-21T20:04:11.496183Z","shell.execute_reply.started":"2023-04-21T20:04:11.490589Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluator\n","\n","La libreria sentence_transformers mette a disposizione diversi costrutti per valutare le performance dei modelli, useremo [EmbeddingSimilarityEvaluator](https://www.sbert.net/docs/package_reference/evaluation.html#sentence_transformers.evaluation.EmbeddingSimilarityEvaluator) che valuta un modello in base alla somiglianza degli embeddings, calcolando la correlazione di Spearman e di Pearson rispetto alle gold standard labels. Le metriche disponibili sono la similarità del coseno, la distanza euclidea e la distanza di Manhattan. \n","\n","Lo score in output è la correlazione di Spearman."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:29:10.153043Z","iopub.status.busy":"2023-04-21T20:29:10.151298Z","iopub.status.idle":"2023-04-21T20:29:10.159811Z","shell.execute_reply":"2023-04-21T20:29:10.157864Z","shell.execute_reply.started":"2023-04-21T20:29:10.152979Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:29:10.382675Z","iopub.status.busy":"2023-04-21T20:29:10.381316Z","iopub.status.idle":"2023-04-21T20:29:10.394044Z","shell.execute_reply":"2023-04-21T20:29:10.392499Z","shell.execute_reply.started":"2023-04-21T20:29:10.382628Z"},"trusted":true},"outputs":[],"source":["evaluator = evaluation.EmbeddingSimilarityEvaluator(dataset_test['sentence1'], dataset_test['sentence2'], [x/5.0 for x in dataset_test['similarity_score']],\n","                                                   main_similarity = evaluation.SimilarityFunction.COSINE, show_progress_bar=True, write_csv=True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Losses\n","\n","A seconda della struttura del dataset che stiamo usando bisogna utilizzare una loss. Nel nostro caso utilizzeremo la [CosineSimilarityLoss](https://www.sbert.net/docs/package_reference/losses.html#cosinesimilarityloss).\n","\n","Lascio l'approfondimento delle losses al post originale, qui metto solo lo schema condiviso nello stesso.\n","\n","> Come si vede dallo schema per la nostra tipologia di dataset potevamo scegliere diverse loss, la CosineSimilarityLoss lavora con la label float mentre le altre due con gli interi, da qui la scelta.\n","\n","<br>\n","\n","![losses](https://huggingface.co/blog/assets/95_training_st_models/datasets_table.png)\n","\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:18:53.549246Z","iopub.status.busy":"2023-04-21T20:18:53.548780Z","iopub.status.idle":"2023-04-21T20:18:53.564928Z","shell.execute_reply":"2023-04-21T20:18:53.563464Z","shell.execute_reply.started":"2023-04-21T20:18:53.549211Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import losses"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:18:54.029685Z","iopub.status.busy":"2023-04-21T20:18:54.029281Z","iopub.status.idle":"2023-04-21T20:18:54.036516Z","shell.execute_reply":"2023-04-21T20:18:54.034909Z","shell.execute_reply.started":"2023-04-21T20:18:54.029652Z"},"trusted":true},"outputs":[],"source":["train_loss = losses.CosineSimilarityLoss(model = model)"]},{"cell_type":"markdown","metadata":{},"source":["## Fit the model\n","\n","La parte più complicata è finita, ora non ci resta che far partire l'addestramento.\n","Impostiamo alcuni iperparametri, il più interessante è **warmup_step**. In pratica dopo un certo numero di passi (su molti forum consigliano il 10% del train) il learning rate viene ridotto linearmente fino allo 0."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:28:21.477757Z","iopub.status.busy":"2023-04-21T20:28:21.477231Z","iopub.status.idle":"2023-04-21T20:28:21.484944Z","shell.execute_reply":"2023-04-21T20:28:21.483316Z","shell.execute_reply.started":"2023-04-21T20:28:21.477719Z"},"trusted":true},"outputs":[],"source":["num_epochs = 10\n","evaluation_steps = 500\n","\n","warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-21T20:29:14.680458Z","iopub.status.busy":"2023-04-21T20:29:14.680016Z","iopub.status.idle":"2023-04-21T20:45:53.218255Z","shell.execute_reply":"2023-04-21T20:45:53.216356Z","shell.execute_reply.started":"2023-04-21T20:29:14.680421Z"},"trusted":true},"outputs":[],"source":["model.fit(train_objectives=[(train_dataloader, train_loss)], evaluator= evaluator, evaluation_steps = evaluation_steps,\n","          epochs=num_epochs, steps_per_epoch= 1500, warmup_steps=warmup_steps, save_best_model=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-04-21T20:45:55.896776Z","iopub.status.idle":"2023-04-21T20:45:55.897368Z","shell.execute_reply":"2023-04-21T20:45:55.897077Z","shell.execute_reply.started":"2023-04-21T20:45:55.897050Z"},"trusted":true},"outputs":[],"source":["# salva in locale\n","#model.save(\"my-awesome-sentence-transformer\")"]},{"cell_type":"markdown","metadata":{},"source":["## Condividi sull'Hub\n","\n","Per condividere i nostri modelli sull'Huggingface Hub c'è bisogno di un token, lo troviamo sul nostro profilo HuggingFace-->Settings--> Access Token.\n","\n","> Non dimenticate di compilare una bella model card! :blush:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#from huggingface_hub import login\n","#login('yourHFtoken')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T08:06:00.841622Z","iopub.status.busy":"2023-03-21T08:06:00.841272Z","iopub.status.idle":"2023-03-21T08:06:37.968369Z","shell.execute_reply":"2023-03-21T08:06:37.966860Z","shell.execute_reply.started":"2023-03-21T08:06:00.841587Z"},"trusted":true},"outputs":[],"source":["#model.save_to_hub('my-awesome-sentence-transformer', organization='yourUsername', train_datasets=[stsb_multi_mt])"]},{"cell_type":"markdown","metadata":{},"source":["## Utilizzo\n","\n","Per utilizzare il nostro Sentence Transformer possiamo utilizzare sia l'omonima libreria che Transformsers di HuggingFace, io consiglio la prima opzione.\n","\n","### Utilizzo con sentence-transformers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#!pip install -U sentence-transformers\n","\n","#from sentence_transformers import SentenceTransformer\n","#sentences = [\"Una ragazza si acconcia i capelli.\", \"Una ragazza si sta spazzolando i capelli.\"]\n","\n","#model = SentenceTransformer('yourUsername/my-awesome-sentence-transformer')\n","#embeddings = model.encode(sentences)\n","#print(embeddings)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Utilizzo con tranformers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"\n","from transformers import AutoTokenizer, AutoModel\n","import torch\n","\n","\n","#Mean Pooling - Take attention mask into account for correct averaging\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","\n","# Sentences we want sentence embeddings for\n","sentences = ['Una ragazza si acconcia i capelli.', 'Una ragazza si sta spazzolando i capelli.']\n","\n","# Load model from HuggingFace Hub\n","tokenizer = AutoTokenizer.from_pretrained('yourUsername/my-awesome-sentence-transformer')\n","model = AutoModel.from_pretrained('yourUsername/my-awesome-sentence-transformer')\n","\n","# Tokenize sentences\n","encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n","\n","# Compute token embeddings\n","with torch.no_grad():\n","    model_output = model(**encoded_input)\n","\n","# Perform pooling. In this case, mean pooling.\n","sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","\n","print(\"Sentence embeddings:\")\n","print(sentence_embeddings)\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["#### Altri riferimenti\n","\n","* [Sentence embedding fine tuning for the french language](https://lajavaness.medium.com/sentence-embedding-fine-tuning-for-the-french-language-65e20b724e88)\n","\n","* [Sentence Transformers and Embedding Evaluation](https://txt.cohere.com/sentence-transformers-embedding-evaluation/)\n","\n","<br>\n","\n","![huggingface](https://huggingface.co/front/thumbnails/v2-2.png)\n","\n","<br>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
